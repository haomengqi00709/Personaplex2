#!/usr/bin/env python3
"""
PersonaPlex ç‹¬ç«‹å®æ—¶ç¿»è¯‘æœº
ä¸ä¾èµ–å®˜æ–¹ä»£ç åº“ï¼Œç›´æ¥ä½¿ç”¨æ¨¡å‹è¿›è¡Œç¿»è¯‘
"""

import os
import torch
import numpy as np
import soundfile as sf
import gradio as gr
from transformers import AutoModel, AutoConfig
from huggingface_hub import login
import warnings
warnings.filterwarnings("ignore")

# å…¨å±€å˜é‡
MODEL_ID = "nvidia/personaplex-7b-v1"
HF_TOKEN = os.getenv("HF_TOKEN")
model = None
device = "cuda" if torch.cuda.is_available() else "cpu"

def load_model():
    """åŠ è½½æ¨¡å‹ï¼ˆä¸ä¾èµ– processorï¼‰"""
    global model
    
    if model is not None:
        memory_info = ""
        if torch.cuda.is_available():
            memory_used = torch.cuda.memory_allocated(0) / 1e9
            memory_info = f"\næ˜¾å­˜: {memory_used:.2f} GB"
        return f"âœ… æ¨¡å‹å·²åŠ è½½{memory_info}"
    
    try:
        # è®¤è¯
        if HF_TOKEN:
            login(token=HF_TOKEN)
        
        print("ğŸ“¥ åŠ è½½æ¨¡å‹...")
        
        # ä½¿ç”¨ AutoModel è‡ªåŠ¨æ£€æµ‹æ¨¡å‹ç±»å‹
        # è™½ç„¶ä¼šæœ‰è­¦å‘Šï¼Œä½†æ¨¡å‹å¯ä»¥åŠ è½½
        model = AutoModel.from_pretrained(
            MODEL_ID,
            torch_dtype=torch.float16,
            device_map="auto",
            low_cpu_mem_usage=True,
            trust_remote_code=True
        )
        model.eval()
        
        memory_info = ""
        if torch.cuda.is_available():
            memory_used = torch.cuda.memory_allocated(0) / 1e9
            memory_info = f"\næ˜¾å­˜: {memory_used:.2f} GB"
        
        return f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼{memory_info}\n\nâš ï¸ æ³¨æ„: ç”±äºç¼ºå°‘ processorï¼Œæ¨ç†åŠŸèƒ½å—é™ã€‚\nå»ºè®®ä½¿ç”¨æ–‡æœ¬æç¤ºæ–¹å¼æµ‹è¯•æ¨¡å‹èƒ½åŠ›ã€‚"
        
    except Exception as e:
        return f"âŒ åŠ è½½å¤±è´¥: {str(e)}"

def process_audio_basic(audio_file, text_prompt):
    """åŸºç¡€éŸ³é¢‘å¤„ç†ï¼ˆä¸ä¾èµ– processorï¼‰"""
    try:
        # è¯»å–éŸ³é¢‘
        audio_data, sr = sf.read(audio_file)
        if len(audio_data.shape) > 1:
            audio_data = np.mean(audio_data, axis=1)
        
        # é‡é‡‡æ ·åˆ° 24kHz
        if sr != 24000:
            import librosa
            audio_data = librosa.resample(audio_data, orig_sr=sr, target_sr=24000)
            sr = 24000
        
        # è½¬æ¢ä¸º tensor
        audio_tensor = torch.from_numpy(audio_data).float().unsqueeze(0).to(device)
        
        return audio_tensor, sr, True
    except Exception as e:
        return None, None, False

def translate_audio(audio_file, source_lang, target_lang, custom_prompt):
    """ç¿»è¯‘éŸ³é¢‘"""
    global model
    
    if model is None:
        return None, "âŒ è¯·å…ˆåŠ è½½æ¨¡å‹ï¼ç‚¹å‡»'åŠ è½½æ¨¡å‹'æŒ‰é’®"
    
    if audio_file is None:
        return None, "âŒ è¯·å½•åˆ¶æˆ–ä¸Šä¼ éŸ³é¢‘"
    
    try:
        # å¤„ç†éŸ³é¢‘
        audio_tensor, sr, success = process_audio_basic(audio_file, None)
        if not success:
            return None, "âŒ éŸ³é¢‘å¤„ç†å¤±è´¥"
        
        # æ„å»ºç¿»è¯‘æç¤º
        if custom_prompt:
            text_prompt = custom_prompt
        else:
            text_prompt = f"You are a real-time translator. Translate from {source_lang} to {target_lang}. Speak naturally and clearly in {target_lang}."
        
        # ç”±äºæ²¡æœ‰ processorï¼Œæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨å‡†å¤‡è¾“å…¥
        # è¿™é‡Œä½¿ç”¨æ¨¡å‹çš„ forward æ–¹æ³•
        # æ³¨æ„ï¼šè¿™å¯èƒ½éœ€è¦æ ¹æ®å®é™…æ¨¡å‹ç»“æ„è°ƒæ•´
        
        print(f"å¤„ç†ç¿»è¯‘: {source_lang} -> {target_lang}")
        print(f"éŸ³é¢‘é•¿åº¦: {audio_tensor.shape[1] / sr:.2f}ç§’")
        print(f"æç¤º: {text_prompt}")
        
        # å°è¯•è°ƒç”¨æ¨¡å‹è¿›è¡Œæ¨ç†
        with torch.no_grad():
            try:
                # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æœ‰ generate æ–¹æ³•
                if hasattr(model, 'generate'):
                    # å°è¯•æ„å»ºåŸºç¡€è¾“å…¥
                    # PersonaPlex å¯èƒ½éœ€è¦ audio_codes å’Œ text tokens
                    # è¿™é‡Œæˆ‘ä»¬å°è¯•æœ€ç®€å•çš„è°ƒç”¨æ–¹å¼
                    
                    # å°†éŸ³é¢‘è½¬æ¢ä¸ºåˆé€‚çš„æ ¼å¼
                    # æ¨¡å‹å¯èƒ½éœ€è¦éŸ³é¢‘ç¼–ç åçš„ tokensï¼Œè€Œä¸æ˜¯åŸå§‹éŸ³é¢‘
                    # ç”±äºæ²¡æœ‰ processorï¼Œæˆ‘ä»¬å°è¯•ç›´æ¥ä¼ é€’éŸ³é¢‘ tensor
                    
                    # å°è¯•è°ƒç”¨æ¨¡å‹ï¼ˆå¯èƒ½éœ€è¦è°ƒæ•´è¾“å…¥æ ¼å¼ï¼‰
                    try:
                        # æ–¹æ³•1: å°è¯•ä½¿ç”¨ generateï¼ˆå¦‚æœæ¨¡å‹æ”¯æŒï¼‰
                        # æ³¨æ„ï¼šè¿™å¯èƒ½éœ€è¦ç‰¹å®šçš„è¾“å…¥æ ¼å¼
                        result_text = f"""
âœ… æ¨¡å‹å·²åŠ è½½å¹¶å‡†å¤‡å°±ç»ª

ğŸ“ ç¿»è¯‘è®¾ç½®:
- æºè¯­è¨€: {source_lang}
- ç›®æ ‡è¯­è¨€: {target_lang}
- æç¤º: {text_prompt}

âš ï¸ å½“å‰é™åˆ¶:
ç”±äºç¼ºå°‘ processorï¼Œæ— æ³•å®Œæˆå®Œæ•´æ¨ç†ã€‚
æ¨¡å‹å·²æˆåŠŸåŠ è½½ï¼ˆ{torch.cuda.memory_allocated(0) / 1e9:.2f} GB æ˜¾å­˜ï¼‰ï¼Œ
ä½†éœ€è¦ processor æ¥å¤„ç†éŸ³é¢‘è¾“å…¥å’Œç”Ÿæˆè¾“å‡ºã€‚

ğŸ’¡ è§£å†³æ–¹æ¡ˆ:
1. å‡çº§ transformers: pip install --upgrade transformers
2. æˆ–æŸ¥çœ‹æ¨¡å‹é…ç½®äº†è§£è¾“å…¥æ ¼å¼
3. æ¨¡å‹æ–‡ä»¶ä½ç½®: ~/.cache/huggingface/hub/models--nvidia--personaplex-7b-v1/
"""
                        
                        # ç”Ÿæˆå ä½éŸ³é¢‘è¡¨ç¤ºå¤„ç†å®Œæˆ
                        sample_rate = 24000
                        duration = 1.5
                        output_audio = np.sin(2 * np.pi * 440 * np.linspace(0, duration, int(sample_rate * duration)))
                        output_audio = output_audio.astype(np.float32)
                        
                        output_path = "/tmp/translation_output.wav"
                        sf.write(output_path, output_audio, sample_rate)
                        
                        return output_path, result_text
                        
                    except Exception as e:
                        return None, f"âŒ æ¨¡å‹è°ƒç”¨å¤±è´¥: {str(e)}\n\næ¨¡å‹å·²åŠ è½½ï¼Œä½†éœ€è¦æ­£ç¡®çš„è¾“å…¥æ ¼å¼ã€‚"
                else:
                    return None, "âŒ æ¨¡å‹æ²¡æœ‰ generate æ–¹æ³•\n\næ¨¡å‹å·²åŠ è½½ï¼Œä½†æ— æ³•è¿›è¡Œæ¨ç†ã€‚"
                
            except Exception as e:
                import traceback
                traceback.print_exc()
                return None, f"âŒ æ¨ç†è¿‡ç¨‹å‡ºé”™: {str(e)}"
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return None, f"âŒ å¤„ç†å¤±è´¥: {str(e)}"

def get_model_info():
    """è·å–æ¨¡å‹ä¿¡æ¯"""
    info = "## æ¨¡å‹ä¿¡æ¯\n\n"
    
    if model is not None:
        info += "âœ… **æ¨¡å‹å·²åŠ è½½**\n\n"
        info += f"**æ¨¡å‹ ID**: {MODEL_ID}\n"
        info += f"**è®¾å¤‡**: {device}\n"
        
        if torch.cuda.is_available():
            memory_used = torch.cuda.memory_allocated(0) / 1e9
            memory_reserved = torch.cuda.memory_reserved(0) / 1e9
            info += f"**æ˜¾å­˜ä½¿ç”¨**: {memory_used:.2f} GB / {memory_reserved:.2f} GB\n"
    else:
        info += "âŒ **æ¨¡å‹æœªåŠ è½½**\n\n"
        info += "ç‚¹å‡»'åŠ è½½æ¨¡å‹'æŒ‰é’®å¼€å§‹"
    
    return info

# åˆ›å»ºç•Œé¢
with gr.Blocks(title="PersonaPlex å®æ—¶ç¿»è¯‘æœº", theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ğŸŒ PersonaPlex å®æ—¶ç¿»è¯‘æœº
    
    ç‹¬ç«‹è¿è¡Œç‰ˆæœ¬ - ä¸ä¾èµ–å®˜æ–¹ä»£ç åº“
    
    **åŠŸèƒ½**: è¯­éŸ³è¾“å…¥ â†’ å®æ—¶ç¿»è¯‘ â†’ è¯­éŸ³è¾“å‡º
    """)
    
    with gr.Row():
        with gr.Column(scale=1):
            gr.Markdown("### æ¨¡å‹æ§åˆ¶")
            load_btn = gr.Button("ğŸ”„ åŠ è½½æ¨¡å‹", variant="primary", size="lg")
            status = gr.Textbox(label="çŠ¶æ€", value="âŒ æ¨¡å‹æœªåŠ è½½", interactive=False, lines=4)
            model_info = gr.Markdown(get_model_info())
        
        with gr.Column(scale=2):
            gr.Markdown("### ç¿»è¯‘è®¾ç½®")
            
            with gr.Row():
                source_lang = gr.Dropdown(
                    label="æºè¯­è¨€",
                    choices=["English", "Chinese", "Spanish", "French", "German", "Japanese", "Korean", "Russian"],
                    value="English"
                )
                
                target_lang = gr.Dropdown(
                    label="ç›®æ ‡è¯­è¨€",
                    choices=["English", "Chinese", "Spanish", "French", "German", "Japanese", "Korean", "Russian"],
                    value="Chinese"
                )
            
            custom_prompt = gr.Textbox(
                label="è‡ªå®šä¹‰æç¤ºï¼ˆå¯é€‰ï¼‰",
                placeholder="ä¾‹å¦‚: Translate naturally, maintain the speaker's tone and emotion.",
                lines=2
            )
            
            audio_input = gr.Audio(
                label="ğŸ¤ è¯´è¯ï¼ˆå½•åˆ¶æˆ–ä¸Šä¼ ï¼‰",
                type="filepath",
                sources=["microphone", "upload"],
                format="wav"
            )
            
            translate_btn = gr.Button("ğŸš€ å¼€å§‹ç¿»è¯‘", variant="primary", size="lg")
    
    with gr.Row():
        with gr.Column():
            gr.Markdown("### ç¿»è¯‘ç»“æœ")
            audio_output = gr.Audio(label="ğŸ”Š ç¿»è¯‘åçš„è¯­éŸ³", type="filepath", format="wav")
            text_output = gr.Textbox(label="ğŸ“ ç¿»è¯‘æ–‡æœ¬/çŠ¶æ€", lines=6, interactive=False)
    
    gr.Markdown("""
    ---
    ### ğŸ“ ä½¿ç”¨è¯´æ˜
    
    1. **åŠ è½½æ¨¡å‹**: ç‚¹å‡»"åŠ è½½æ¨¡å‹"æŒ‰é’®ï¼ˆé¦–æ¬¡éœ€è¦å‡ åˆ†é’Ÿï¼‰
    2. **é€‰æ‹©è¯­è¨€**: é€‰æ‹©æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€
    3. **å½•åˆ¶éŸ³é¢‘**: ç‚¹å‡»éº¦å…‹é£å›¾æ ‡å½•åˆ¶ï¼Œæˆ–ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶
    4. **å¼€å§‹ç¿»è¯‘**: ç‚¹å‡»"å¼€å§‹ç¿»è¯‘"æŒ‰é’®
    5. **æŸ¥çœ‹ç»“æœ**: æ’­æ”¾ç¿»è¯‘åçš„è¯­éŸ³ï¼ŒæŸ¥çœ‹ç¿»è¯‘æ–‡æœ¬
    
    ### âš ï¸ æ³¨æ„äº‹é¡¹
    
    - æ¨¡å‹å·²æˆåŠŸåŠ è½½ï¼Œä½†ç”±äºç¼ºå°‘ processorï¼Œå®Œæ•´æ¨ç†åŠŸèƒ½å¯èƒ½å—é™
    - å¦‚æœé‡åˆ°é—®é¢˜ï¼Œå¯èƒ½éœ€è¦äº†è§£æ¨¡å‹çš„è¾“å…¥æ ¼å¼
    - å»ºè®®ä½¿ç”¨ 24kHz WAV æ ¼å¼çš„éŸ³é¢‘
    """)
    
    # äº‹ä»¶ç»‘å®š
    def update_info():
        return get_model_info()
    
    load_btn.click(
        fn=load_model,
        outputs=status
    ).then(
        fn=update_info,
        outputs=model_info
    )
    
    translate_btn.click(
        fn=translate_audio,
        inputs=[audio_input, source_lang, target_lang, custom_prompt],
        outputs=[audio_output, text_output]
    )

if __name__ == "__main__":
    print("="*60)
    print("PersonaPlex å®æ—¶ç¿»è¯‘æœº - ç‹¬ç«‹ç‰ˆæœ¬")
    print("ç«¯å£: 5001")
    print("="*60)
    
    if not HF_TOKEN:
        print("âš ï¸  è­¦å‘Š: HF_TOKEN æœªè®¾ç½®")
        print("   æŸäº›åŠŸèƒ½å¯èƒ½æ— æ³•ä½¿ç”¨")
    
    demo.launch(
        server_name="0.0.0.0",
        server_port=5001,
        share=False
    )

