#!/usr/bin/env python3
"""
PersonaPlex ç®€å•è¯­éŸ³å¯¹è¯
ä¸€ä¸ªæŒ‰é’®ï¼šå¼€å§‹/åœæ­¢è¯´è¯
å·¦è¾¹ï¼šæ‚¨è¯´çš„è¯ | å³è¾¹ï¼šAIå›å¤
"""

import os
import torch
import numpy as np
import soundfile as sf
import gradio as gr
from transformers import MoshiForConditionalGeneration, AutoModel
from huggingface_hub import login
import warnings
warnings.filterwarnings("ignore")

MODEL_ID = "nvidia/personaplex-7b-v1"
HF_TOKEN = os.getenv("HF_TOKEN")
model = None
device = "cuda" if torch.cuda.is_available() else "cpu"
model_loading = False
model_status = "æœªåŠ è½½"

def load_model():
    """åŠ è½½æ¨¡å‹"""
    global model, model_status
    
    if model is not None:
        mem = torch.cuda.memory_allocated(0) / 1e9 if torch.cuda.is_available() else 0
        return f"âœ… æ¨¡å‹å·²åŠ è½½ ({mem:.2f} GB)"
    
    try:
        if HF_TOKEN:
            login(token=HF_TOKEN)
        
        print("ğŸ“¥ åŠ è½½æ¨¡å‹...")
        model_status = "åŠ è½½ä¸­..."
        
        # é¦–å…ˆæ£€æŸ¥ Transformers ç‰ˆæœ¬
        import transformers
        transformers_version = transformers.__version__
        print(f"Transformers ç‰ˆæœ¬: {transformers_version}")
        
        # å°è¯•åŠ è½½æ¨¡å‹
        try:
            # æ–¹æ³•1: ä½¿ç”¨ AutoModel + trust_remote_code
            print("å°è¯•ä½¿ç”¨ AutoModel åŠ è½½...")
            model = AutoModel.from_pretrained(
                MODEL_ID,
                torch_dtype=torch.float16,
                device_map="auto",
                low_cpu_mem_usage=True,
                trust_remote_code=True
            )
            print("âœ… ä½¿ç”¨ AutoModel åŠ è½½æˆåŠŸ")
        except Exception as e1:
            print(f"âš ï¸  AutoModel å¤±è´¥: {e1}")
            
            # æ–¹æ³•2: å°è¯•ä»æºç å®‰è£…çš„ Transformers
            error_msg = str(e1)
            if "does not recognize this architecture" in error_msg or "personaplex" in error_msg.lower():
                return f"""âŒ Transformers ç‰ˆæœ¬ä¸æ”¯æŒ PersonaPlex æ¶æ„

å½“å‰ç‰ˆæœ¬: {transformers_version}

è§£å†³æ–¹æ¡ˆ:
1. å‡çº§ Transformers:
   pip install --upgrade transformers

2. æˆ–ä»æºç å®‰è£…æœ€æ–°ç‰ˆæœ¬:
   pip install git+https://github.com/huggingface/transformers.git

3. ç„¶åé‡æ–°å¯åŠ¨ç¨‹åº"""
            else:
                raise e1
        
        model.eval()
        mem = torch.cuda.memory_allocated(0) / 1e9 if torch.cuda.is_available() else 0
        model_status = "å·²åŠ è½½"
        return f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼({mem:.2f} GB)"
        
    except Exception as e:
        model_status = "åŠ è½½å¤±è´¥"
        error_msg = str(e)
        if "does not recognize this architecture" in error_msg:
            return f"""âŒ Transformers ä¸æ”¯æŒ PersonaPlex æ¶æ„

è¯·æ‰§è¡Œä»¥ä¸‹å‘½ä»¤å‡çº§ Transformers:
pip install --upgrade transformers

æˆ–ä»æºç å®‰è£…:
pip install git+https://github.com/huggingface/transformers.git

ç„¶åé‡æ–°å¯åŠ¨ç¨‹åº"""
        return f"âŒ å¤±è´¥: {error_msg}"

def process_voice(audio):
    """å¤„ç†è¯­éŸ³"""
    global model
    
    if model is None:
        return "âŒ è¯·å…ˆåŠ è½½æ¨¡å‹", "âŒ æ¨¡å‹æœªåŠ è½½"
    
    if audio is None:
        return "", ""
    
    try:
        # è¯»å–éŸ³é¢‘
        audio_data, sr = sf.read(audio)
        if len(audio_data.shape) > 1:
            audio_data = np.mean(audio_data, axis=1)
        
        # é‡é‡‡æ ·åˆ° 24kHz
        if sr != 24000:
            import librosa
            audio_data = librosa.resample(audio_data, orig_sr=sr, target_sr=24000)
            sr = 24000
        
        duration = len(audio_data) / sr
        user_text = f"ğŸ¤ è¯­éŸ³è¾“å…¥ ({duration:.2f}ç§’)"
        
        # å°è¯•è°ƒç”¨æ¨¡å‹ï¼ˆå³ä½¿æ²¡æœ‰processorï¼‰
        try:
            # å°†éŸ³é¢‘è½¬æ¢ä¸ºtensor
            audio_tensor = torch.from_numpy(audio_data).float().unsqueeze(0).to(device)
            
            # å°è¯•ç›´æ¥è°ƒç”¨æ¨¡å‹ï¼ˆéœ€è¦æ ¹æ®å®é™…æ¶æ„è°ƒæ•´ï¼‰
            # ç”±äºPersonaPlexæ¶æ„ç‰¹æ®Šï¼Œè¿™é‡Œæä¾›ä¸€ä¸ªåŸºç¡€å°è¯•
            with torch.no_grad():
                # å°è¯•ä½¿ç”¨æ¨¡å‹çš„forwardæ–¹æ³•
                # æ³¨æ„ï¼šè¿™å¯èƒ½éœ€è¦ç‰¹å®šçš„è¾“å…¥æ ¼å¼
                try:
                    # åˆ›å»ºä¸€ä¸ªç®€å•çš„è¾“å…¥ï¼ˆå¯èƒ½éœ€è¦è°ƒæ•´ï¼‰
                    # PersonaPlexå¯èƒ½éœ€è¦audio codeså’Œtext tokens
                    # è¿™é‡Œæˆ‘ä»¬å°è¯•æœ€ç®€å•çš„è°ƒç”¨
                    
                    # ç”±äºæ²¡æœ‰processorï¼Œæˆ‘ä»¬æ— æ³•æ­£ç¡®ç¼–ç è¾“å…¥
                    # ä½†å¯ä»¥æ˜¾ç¤ºæ¨¡å‹å·²å‡†å¤‡å¥½
                    ai_text = f"âœ… å·²æ”¶åˆ°è¯­éŸ³ ({duration:.2f}ç§’)\n\næ¨¡å‹å·²åŠ è½½å¹¶å‡†å¤‡å¤„ç†ã€‚\n\nâš ï¸ ç”±äºç¼ºå°‘processorï¼Œæ— æ³•å®Œæˆå®Œæ•´æ¨ç†ã€‚\næ¨¡å‹éœ€è¦ç‰¹å®šçš„éŸ³é¢‘ç¼–ç æ ¼å¼ã€‚"
                    
                except Exception as e:
                    ai_text = f"âœ… æ¨¡å‹å·²åŠ è½½\n\nâš ï¸ æ¨ç†éœ€è¦processoræˆ–äº†è§£è¾“å…¥æ ¼å¼ã€‚\né”™è¯¯: {str(e)}"
        except Exception as e:
            ai_text = f"âœ… éŸ³é¢‘å·²å¤„ç†\n\nâš ï¸ æ¨¡å‹è°ƒç”¨éœ€è¦ç‰¹å®šæ ¼å¼ã€‚\n{str(e)}"
        
        return user_text, ai_text
        
    except Exception as e:
        return f"âŒ é”™è¯¯: {str(e)}", ""

# å¯åŠ¨æ—¶è‡ªåŠ¨åŠ è½½æ¨¡å‹
def auto_load_model():
    """ç¨‹åºå¯åŠ¨æ—¶è‡ªåŠ¨åŠ è½½æ¨¡å‹"""
    print("="*60)
    print("è‡ªåŠ¨åŠ è½½æ¨¡å‹...")
    print("="*60)
    return load_model()

# åˆ›å»ºç•Œé¢
with gr.Blocks(title="PersonaPlex è¯­éŸ³å¯¹è¯", theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ™ï¸ PersonaPlex è¯­éŸ³å¯¹è¯")
    
    # çŠ¶æ€æ˜¾ç¤ºï¼ˆè‡ªåŠ¨åŠ è½½ï¼‰
    status = gr.Textbox(
        label="æ¨¡å‹çŠ¶æ€", 
        value="æ­£åœ¨åŠ è½½æ¨¡å‹...", 
        interactive=False,
        lines=3
    )
    
    # æ‰‹åŠ¨é‡æ–°åŠ è½½æŒ‰é’®ï¼ˆå¯é€‰ï¼‰
    load_btn = gr.Button("ğŸ”„ é‡æ–°åŠ è½½æ¨¡å‹", variant="secondary", size="sm")
    
    gr.Markdown("---")
    
    # å¯¹è¯åŒºåŸŸ
    with gr.Row():
        with gr.Column():
            gr.Markdown("### ğŸ‘¤ æ‚¨è¯´çš„è¯")
            user_text = gr.Textbox(label="", lines=12, interactive=False, placeholder="...")
        
        with gr.Column():
            gr.Markdown("### ğŸ¤– AI å›å¤")
            ai_text = gr.Textbox(label="", lines=12, interactive=False, placeholder="...")
    
    # è¯­éŸ³è¾“å…¥
    audio_input = gr.Audio(
        label="",
        type="filepath",
        sources=["microphone"],
        format="wav",
        show_label=False
    )
    
    # äº‹ä»¶
    # å¯åŠ¨æ—¶è‡ªåŠ¨åŠ è½½æ¨¡å‹
    demo.load(fn=auto_load_model, outputs=status)
    
    # æ‰‹åŠ¨é‡æ–°åŠ è½½
    load_btn.click(fn=load_model, outputs=status)
    
    # è¯­éŸ³å¤„ç†
    audio_input.change(
        fn=process_voice,
        inputs=[audio_input],
        outputs=[user_text, ai_text]
    )

if __name__ == "__main__":
    print("="*60)
    print("PersonaPlex è¯­éŸ³å¯¹è¯ - ç«¯å£ 5001")
    print("="*60)
    
    demo.launch(
        server_name="0.0.0.0",
        server_port=5001,
        share=False
    )

