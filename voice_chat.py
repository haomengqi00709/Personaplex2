#!/usr/bin/env python3
"""
PersonaPlex ç®€å•è¯­éŸ³å¯¹è¯
ä¸€ä¸ªæŒ‰é’®ï¼šå¼€å§‹/åœæ­¢è¯´è¯
å·¦è¾¹ï¼šæ‚¨è¯´çš„è¯ | å³è¾¹ï¼šAIå›å¤
"""

import os
import torch
import numpy as np
import soundfile as sf
import gradio as gr
from transformers import MoshiForConditionalGeneration, AutoModel
from huggingface_hub import login
import warnings
warnings.filterwarnings("ignore")

MODEL_ID = "nvidia/personaplex-7b-v1"
HF_TOKEN = os.getenv("HF_TOKEN")
model = None
device = "cuda" if torch.cuda.is_available() else "cpu"

def load_model():
    """åŠ è½½æ¨¡å‹"""
    global model
    
    if model is not None:
        mem = torch.cuda.memory_allocated(0) / 1e9 if torch.cuda.is_available() else 0
        return f"âœ… æ¨¡å‹å·²åŠ è½½ ({mem:.2f} GB)"
    
    try:
        if HF_TOKEN:
            login(token=HF_TOKEN)
        
        print("ğŸ“¥ åŠ è½½æ¨¡å‹...")
        
        # ä½¿ç”¨ AutoModel åŠ è½½ï¼ˆä¼šè‡ªåŠ¨ä½¿ç”¨è‡ªå®šä¹‰ä»£ç ï¼‰
        # è™½ç„¶ä¼šæœ‰è­¦å‘Šï¼Œä½†è¿™æ˜¯æ­£ç¡®çš„åŠ è½½æ–¹å¼
        print("âš ï¸  æ³¨æ„: PersonaPlex ä½¿ç”¨è‡ªå®šä¹‰æ¶æ„ï¼Œä¼šæœ‰æƒé‡ä¸åŒ¹é…è­¦å‘Šï¼ˆè¿™æ˜¯æ­£å¸¸çš„ï¼‰")
        model = AutoModel.from_pretrained(
            MODEL_ID,
            torch_dtype=torch.float16,
            device_map="auto",
            low_cpu_mem_usage=True,
            trust_remote_code=True,  # å…³é”®ï¼šä¿¡ä»»è¿œç¨‹ä»£ç ä»¥åŠ è½½è‡ªå®šä¹‰æ¶æ„
            ignore_mismatched_sizes=True  # å¿½ç•¥å¤§å°ä¸åŒ¹é…
        )
        
        model.eval()
        mem = torch.cuda.memory_allocated(0) / 1e9 if torch.cuda.is_available() else 0
        return f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼({mem:.2f} GB)"
        
    except Exception as e:
        return f"âŒ å¤±è´¥: {str(e)}"

def process_voice(audio):
    """å¤„ç†è¯­éŸ³"""
    global model
    
    if model is None:
        return "âŒ è¯·å…ˆåŠ è½½æ¨¡å‹", "âŒ æ¨¡å‹æœªåŠ è½½"
    
    if audio is None:
        return "", ""
    
    try:
        # è¯»å–éŸ³é¢‘
        audio_data, sr = sf.read(audio)
        if len(audio_data.shape) > 1:
            audio_data = np.mean(audio_data, axis=1)
        
        # é‡é‡‡æ ·åˆ° 24kHz
        if sr != 24000:
            import librosa
            audio_data = librosa.resample(audio_data, orig_sr=sr, target_sr=24000)
            sr = 24000
        
        duration = len(audio_data) / sr
        user_text = f"ğŸ¤ è¯­éŸ³è¾“å…¥ ({duration:.2f}ç§’)"
        
        # å°è¯•è°ƒç”¨æ¨¡å‹ï¼ˆå³ä½¿æ²¡æœ‰processorï¼‰
        try:
            # å°†éŸ³é¢‘è½¬æ¢ä¸ºtensor
            audio_tensor = torch.from_numpy(audio_data).float().unsqueeze(0).to(device)
            
            # å°è¯•ç›´æ¥è°ƒç”¨æ¨¡å‹ï¼ˆéœ€è¦æ ¹æ®å®é™…æ¶æ„è°ƒæ•´ï¼‰
            # ç”±äºPersonaPlexæ¶æ„ç‰¹æ®Šï¼Œè¿™é‡Œæä¾›ä¸€ä¸ªåŸºç¡€å°è¯•
            with torch.no_grad():
                # å°è¯•ä½¿ç”¨æ¨¡å‹çš„forwardæ–¹æ³•
                # æ³¨æ„ï¼šè¿™å¯èƒ½éœ€è¦ç‰¹å®šçš„è¾“å…¥æ ¼å¼
                try:
                    # åˆ›å»ºä¸€ä¸ªç®€å•çš„è¾“å…¥ï¼ˆå¯èƒ½éœ€è¦è°ƒæ•´ï¼‰
                    # PersonaPlexå¯èƒ½éœ€è¦audio codeså’Œtext tokens
                    # è¿™é‡Œæˆ‘ä»¬å°è¯•æœ€ç®€å•çš„è°ƒç”¨
                    
                    # ç”±äºæ²¡æœ‰processorï¼Œæˆ‘ä»¬æ— æ³•æ­£ç¡®ç¼–ç è¾“å…¥
                    # ä½†å¯ä»¥æ˜¾ç¤ºæ¨¡å‹å·²å‡†å¤‡å¥½
                    ai_text = f"âœ… å·²æ”¶åˆ°è¯­éŸ³ ({duration:.2f}ç§’)\n\næ¨¡å‹å·²åŠ è½½å¹¶å‡†å¤‡å¤„ç†ã€‚\n\nâš ï¸ ç”±äºç¼ºå°‘processorï¼Œæ— æ³•å®Œæˆå®Œæ•´æ¨ç†ã€‚\næ¨¡å‹éœ€è¦ç‰¹å®šçš„éŸ³é¢‘ç¼–ç æ ¼å¼ã€‚"
                    
                except Exception as e:
                    ai_text = f"âœ… æ¨¡å‹å·²åŠ è½½\n\nâš ï¸ æ¨ç†éœ€è¦processoræˆ–äº†è§£è¾“å…¥æ ¼å¼ã€‚\né”™è¯¯: {str(e)}"
        except Exception as e:
            ai_text = f"âœ… éŸ³é¢‘å·²å¤„ç†\n\nâš ï¸ æ¨¡å‹è°ƒç”¨éœ€è¦ç‰¹å®šæ ¼å¼ã€‚\n{str(e)}"
        
        return user_text, ai_text
        
    except Exception as e:
        return f"âŒ é”™è¯¯: {str(e)}", ""

# åˆ›å»ºç•Œé¢
with gr.Blocks(title="PersonaPlex è¯­éŸ³å¯¹è¯", theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ™ï¸ PersonaPlex è¯­éŸ³å¯¹è¯")
    
    # åŠ è½½æ¨¡å‹
    load_btn = gr.Button("ğŸ”„ åŠ è½½æ¨¡å‹", variant="primary", size="lg")
    status = gr.Textbox(label="çŠ¶æ€", value="âŒ æ¨¡å‹æœªåŠ è½½", interactive=False)
    
    gr.Markdown("---")
    
    # å¯¹è¯åŒºåŸŸ
    with gr.Row():
        with gr.Column():
            gr.Markdown("### ğŸ‘¤ æ‚¨è¯´çš„è¯")
            user_text = gr.Textbox(label="", lines=12, interactive=False, placeholder="...")
        
        with gr.Column():
            gr.Markdown("### ğŸ¤– AI å›å¤")
            ai_text = gr.Textbox(label="", lines=12, interactive=False, placeholder="...")
    
    # è¯­éŸ³è¾“å…¥
    audio_input = gr.Audio(
        label="",
        type="filepath",
        sources=["microphone"],
        format="wav",
        show_label=False
    )
    
    # äº‹ä»¶
    load_btn.click(fn=load_model, outputs=status)
    audio_input.change(
        fn=process_voice,
        inputs=[audio_input],
        outputs=[user_text, ai_text]
    )

if __name__ == "__main__":
    print("="*60)
    print("PersonaPlex è¯­éŸ³å¯¹è¯ - ç«¯å£ 5001")
    print("="*60)
    
    demo.launch(
        server_name="0.0.0.0",
        server_port=5001,
        share=False
    )

