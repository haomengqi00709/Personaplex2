#!/usr/bin/env python3
"""
PersonaPlex ç®€å•å®æ—¶è¯­éŸ³å¯¹è¯
åªæœ‰ä¸€ä¸ªæŒ‰é”®ï¼šå¼€å§‹/åœæ­¢è¯´è¯
å·¦è¾¹æ˜¾ç¤ºç”¨æˆ·è¯´çš„è¯ï¼Œå³è¾¹æ˜¾ç¤ºAIå›å¤
"""

import os
import torch
import numpy as np
import soundfile as sf
import gradio as gr
from transformers import MoshiForConditionalGeneration, AutoModel
from huggingface_hub import login
import warnings
warnings.filterwarnings("ignore")

# å…¨å±€å˜é‡
MODEL_ID = "nvidia/personaplex-7b-v1"
HF_TOKEN = os.getenv("HF_TOKEN")
model = None
device = "cuda" if torch.cuda.is_available() else "cpu"
is_recording = False

def load_model():
    """åŠ è½½æ¨¡å‹"""
    global model
    
    if model is not None:
        memory_info = ""
        if torch.cuda.is_available():
            memory_used = torch.cuda.memory_allocated(0) / 1e9
            memory_info = f" (æ˜¾å­˜: {memory_used:.2f} GB)"
        return f"âœ… æ¨¡å‹å·²åŠ è½½{memory_info}"
    
    try:
        if HF_TOKEN:
            login(token=HF_TOKEN)
        
        print("ğŸ“¥ åŠ è½½æ¨¡å‹...")
        
        # å°è¯•åŠ è½½æ¨¡å‹
        try:
            from transformers import MoshiForConditionalGeneration
            model = MoshiForConditionalGeneration.from_pretrained(
                MODEL_ID,
                torch_dtype=torch.float16,
                device_map="auto",
                low_cpu_mem_usage=True,
                trust_remote_code=True
            )
        except:
            model = AutoModel.from_pretrained(
                MODEL_ID,
                torch_dtype=torch.float16,
                device_map="auto",
                low_cpu_mem_usage=True,
                trust_remote_code=True
            )
        
        model.eval()
        
        memory_info = ""
        if torch.cuda.is_available():
            memory_used = torch.cuda.memory_allocated(0) / 1e9
            memory_info = f" (æ˜¾å­˜: {memory_used:.2f} GB)"
        
        return f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼{memory_info}"
        
    except Exception as e:
        return f"âŒ åŠ è½½å¤±è´¥: {str(e)}"

def process_voice(audio):
    """å¤„ç†è¯­éŸ³è¾“å…¥å¹¶ç”Ÿæˆå›å¤"""
    global model
    
    if model is None:
        return "âŒ è¯·å…ˆåŠ è½½æ¨¡å‹", "âŒ æ¨¡å‹æœªåŠ è½½"
    
    if audio is None:
        return "", ""
    
    try:
        # è¯»å–éŸ³é¢‘
        audio_data, sr = sf.read(audio)
        if len(audio_data.shape) > 1:
            audio_data = np.mean(audio_data, axis=1)
        
        # é‡é‡‡æ ·åˆ° 24kHz
        if sr != 24000:
            import librosa
            audio_data = librosa.resample(audio_data, orig_sr=sr, target_sr=24000)
            sr = 24000
        
        # ç”¨æˆ·è¯´çš„è¯ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥ç”¨ASRï¼‰
        user_text = f"[éŸ³é¢‘è¾“å…¥: {len(audio_data)/sr:.2f}ç§’]"
        
        # AIå›å¤ï¼ˆç”±äºç¼ºå°‘processorï¼Œè¿™é‡Œæ˜¾ç¤ºçŠ¶æ€ï¼‰
        # å®é™…ä½¿ç”¨æ—¶éœ€è¦processoræˆ–æ‰‹åŠ¨å®ç°æ¨ç†
        ai_text = f"âœ… å·²æ”¶åˆ°æ‚¨çš„è¯­éŸ³\n\nâš ï¸ ç”±äºç¼ºå°‘processorï¼Œæ— æ³•å®Œæˆå®Œæ•´æ¨ç†ã€‚\næ¨¡å‹å·²åŠ è½½ï¼ˆ{torch.cuda.memory_allocated(0)/1e9:.2f} GBï¼‰ï¼Œ\nä½†éœ€è¦processoræ¥å¤„ç†éŸ³é¢‘ã€‚"
        
        return user_text, ai_text
        
    except Exception as e:
        return f"âŒ å¤„ç†å¤±è´¥: {str(e)}", ""

# åˆ›å»ºç®€å•ç•Œé¢
with gr.Blocks(title="PersonaPlex è¯­éŸ³å¯¹è¯", theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ğŸ™ï¸ PersonaPlex å®æ—¶è¯­éŸ³å¯¹è¯
    
    ç®€å•æµ‹è¯•ç•Œé¢
    """)
    
    # æ¨¡å‹åŠ è½½
    with gr.Row():
        load_btn = gr.Button("ğŸ”„ åŠ è½½æ¨¡å‹", variant="primary", size="lg")
        status = gr.Textbox(label="çŠ¶æ€", value="âŒ æ¨¡å‹æœªåŠ è½½", interactive=False)
    
    gr.Markdown("---")
    
    # è¯­éŸ³å¯¹è¯åŒºåŸŸ
    with gr.Row():
        with gr.Column():
            gr.Markdown("### ğŸ‘¤ æ‚¨è¯´çš„è¯")
            user_text = gr.Textbox(label="", lines=10, interactive=False, placeholder="æ‚¨è¯´çš„è¯ä¼šæ˜¾ç¤ºåœ¨è¿™é‡Œ...")
        
        with gr.Column():
            gr.Markdown("### ğŸ¤– AI å›å¤")
            ai_text = gr.Textbox(label="", lines=10, interactive=False, placeholder="AIçš„å›å¤ä¼šæ˜¾ç¤ºåœ¨è¿™é‡Œ...")
    
    # è¯­éŸ³è¾“å…¥
    audio_input = gr.Audio(
        label="",
        type="filepath",
        sources=["microphone"],
        format="wav",
        show_label=False
    )
    
    # å¤„ç†æŒ‰é’®
    process_btn = gr.Button("ğŸš€ å¤„ç†è¯­éŸ³", variant="primary", size="lg")
    
    gr.Markdown("""
    ---
    ### ğŸ“ ä½¿ç”¨è¯´æ˜
    
    1. ç‚¹å‡»"åŠ è½½æ¨¡å‹"ï¼ˆé¦–æ¬¡éœ€è¦å‡ åˆ†é’Ÿï¼‰
    2. ç‚¹å‡»éº¦å…‹é£å›¾æ ‡å½•åˆ¶è¯­éŸ³
    3. ç‚¹å‡»"å¤„ç†è¯­éŸ³"æŒ‰é’®
    4. æŸ¥çœ‹å·¦ä¾§ï¼ˆæ‚¨è¯´çš„è¯ï¼‰å’Œå³ä¾§ï¼ˆAIå›å¤ï¼‰
    """)
    
    # äº‹ä»¶ç»‘å®š
    load_btn.click(fn=load_model, outputs=status)
    process_btn.click(
        fn=process_voice,
        inputs=[audio_input],
        outputs=[user_text, ai_text]
    )

if __name__ == "__main__":
    print("="*60)
    print("PersonaPlex ç®€å•è¯­éŸ³å¯¹è¯")
    print("ç«¯å£: 5001")
    print("="*60)
    
    demo.launch(
        server_name="0.0.0.0",
        server_port=5001,
        share=False
    )

